{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-11T22:27:13.668237Z",
     "start_time": "2025-04-11T22:27:13.660772Z"
    }
   },
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "beb0f9a43bf8f34f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T22:27:16.681254Z",
     "start_time": "2025-04-11T22:27:16.448004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "data_path = r\"C:\\Users\\Melek\\yapayZeka\\karakterAnaliziProje\\İşlenmişVeriler\\tum_filmler_etiketli.csv\"\n",
    "df = pd.read_csv(data_path)"
   ],
   "id": "9c13e4905875778",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T22:27:18.358903Z",
     "start_time": "2025-04-11T22:27:18.328978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "label_map = {label:idx for idx, label in enumerate(df['Etiket'].unique())}\n",
    "df['label'] = df['Etiket'].map(label_map)"
   ],
   "id": "dc663918ea6192e7",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T22:27:20.099800Z",
     "start_time": "2025-04-11T22:27:19.962761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])"
   ],
   "id": "60ac1b5d98fd94bf",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T22:27:27.318431Z",
     "start_time": "2025-04-11T22:27:27.287435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from torch.utils.data import Dataset  # Bu satırı ekleyin\n",
    "import torch\n",
    "\n",
    "class FilmDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Hyperparameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5"
   ],
   "id": "5898aff02d9de675",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T22:27:35.575080Z",
     "start_time": "2025-04-11T22:27:33.192129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Türkçe için alternatif model\n",
    "model_name = \"ytu-ce-cosmos/turkish-base-bert-uncased\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_map))"
   ],
   "id": "7b032748112cfe2a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ytu-ce-cosmos/turkish-base-bert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T22:27:47.022294Z",
     "start_time": "2025-04-11T22:27:38.421037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ],
   "id": "a8ceba58d17c7258",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T22:27:50.915541Z",
     "start_time": "2025-04-11T22:27:50.893741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from torch.utils.data import DataLoader  \n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = FilmDataset(\n",
    "        texts=df['Processed_Sentence'].values,\n",
    "        labels=df['label'].values,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    return DataLoader(ds, batch_size=batch_size)\n",
    "\n",
    "train_data_loader = create_data_loader(train_df, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(test_df, tokenizer, MAX_LEN, BATCH_SIZE)"
   ],
   "id": "93e8d58fce6fbb60",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T22:27:56.328493Z",
     "start_time": "2025-04-11T22:27:56.310076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.optim import Adam\n",
    "optimizer = Adam(model.parameters(), lr=2e-5)"
   ],
   "id": "e2afdd17494c3722",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T22:27:58.783342Z",
     "start_time": "2025-04-11T22:27:58.765351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    \n",
    "    for batch in tqdm(data_loader, desc=\"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    return np.mean(losses)"
   ],
   "id": "37604be1fdd31775",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T22:28:04.353106Z",
     "start_time": "2025-04-11T22:28:04.343100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            actual_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return classification_report(actual_labels, predictions, target_names=label_map.keys()), accuracy_score(actual_labels, predictions)"
   ],
   "id": "b4268c0c0a06e52c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T00:46:46.487810Z",
     "start_time": "2025-04-11T22:28:12.209140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Eğitim döngüsü\n",
    "from tqdm import tqdm\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    train_loss = train_epoch(model, train_data_loader, optimizer, device)\n",
    "    print(f'Train loss: {train_loss}')\n",
    "    \n",
    "    report, acc = eval_model(model, test_data_loader+, device)\n",
    "    print(f'Test Accuracy: {acc:.4f}')\n",
    "    print(report)"
   ],
   "id": "5b0cbe92d7f1c99d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/3390 [00:00<?, ?it/s]C:\\Users\\Melek\\yapayZeka\\karakterAnaliziProje\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Training: 100%|██████████| 3390/3390 [42:32<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.733259539829243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 848/848 [04:20<00:00,  3.26it/s]\n",
      "C:\\Users\\Melek\\yapayZeka\\karakterAnaliziProje\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Melek\\yapayZeka\\karakterAnaliziProje\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Melek\\yapayZeka\\karakterAnaliziProje\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.2184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   distoptik       0.23      0.01      0.03       659\n",
      "       müzik       0.42      0.18      0.25       708\n",
      "   animasyon       0.80      0.31      0.45       843\n",
      "       savaş       0.12      0.03      0.04       613\n",
      "     gerilim       0.13      0.13      0.13       883\n",
      "         suç       0.14      0.38      0.21      1086\n",
      " bilim kurgu       0.19      0.50      0.28      1163\n",
      "     aksiyon       0.00      0.00      0.00       542\n",
      "    romantik       0.29      0.16      0.20      1060\n",
      "        dram       0.00      0.00      0.00       814\n",
      "        spor       0.71      0.43      0.53       894\n",
      "       tarih       0.20      0.28      0.23       962\n",
      "    polisiye       0.14      0.06      0.08       834\n",
      "   fantastik       0.22      0.24      0.23       842\n",
      "      komedi       0.17      0.37      0.23      1044\n",
      "       korku       0.00      0.00      0.00       612\n",
      "\n",
      "    accuracy                           0.22     13559\n",
      "   macro avg       0.24      0.19      0.18     13559\n",
      "weighted avg       0.24      0.22      0.20     13559\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3390/3390 [41:31<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.3419695844340818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 848/848 [04:21<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   distoptik       0.31      0.14      0.19       659\n",
      "       müzik       0.46      0.25      0.32       708\n",
      "   animasyon       0.57      0.45      0.50       843\n",
      "       savaş       0.38      0.17      0.24       613\n",
      "     gerilim       0.27      0.24      0.26       883\n",
      "         suç       0.18      0.47      0.26      1086\n",
      " bilim kurgu       0.26      0.53      0.35      1163\n",
      "     aksiyon       0.41      0.06      0.10       542\n",
      "    romantik       0.38      0.31      0.34      1060\n",
      "        dram       0.33      0.12      0.18       814\n",
      "        spor       0.63      0.48      0.54       894\n",
      "       tarih       0.39      0.29      0.33       962\n",
      "    polisiye       0.22      0.18      0.20       834\n",
      "   fantastik       0.33      0.32      0.33       842\n",
      "      komedi       0.27      0.39      0.32      1044\n",
      "       korku       0.45      0.13      0.20       612\n",
      "\n",
      "    accuracy                           0.31     13559\n",
      "   macro avg       0.36      0.28      0.29     13559\n",
      "weighted avg       0.36      0.31      0.30     13559\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3390/3390 [41:23<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.4058269057653647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 848/848 [04:24<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   distoptik       0.00      0.00      0.00       659\n",
      "       müzik       0.00      0.00      0.00       708\n",
      "   animasyon       0.00      0.00      0.00       843\n",
      "       savaş       0.00      0.00      0.00       613\n",
      "     gerilim       0.00      0.00      0.00       883\n",
      "         suç       0.00      0.00      0.00      1086\n",
      " bilim kurgu       0.09      1.00      0.16      1163\n",
      "     aksiyon       0.00      0.00      0.00       542\n",
      "    romantik       0.00      0.00      0.00      1060\n",
      "        dram       0.00      0.00      0.00       814\n",
      "        spor       0.00      0.00      0.00       894\n",
      "       tarih       0.00      0.00      0.00       962\n",
      "    polisiye       0.00      0.00      0.00       834\n",
      "   fantastik       0.00      0.00      0.00       842\n",
      "      komedi       0.00      0.00      0.00      1044\n",
      "       korku       0.00      0.00      0.00       612\n",
      "\n",
      "    accuracy                           0.09     13559\n",
      "   macro avg       0.01      0.06      0.01     13559\n",
      "weighted avg       0.01      0.09      0.01     13559\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Melek\\yapayZeka\\karakterAnaliziProje\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Melek\\yapayZeka\\karakterAnaliziProje\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Melek\\yapayZeka\\karakterAnaliziProje\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "25b9f11fb5b44e12"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
