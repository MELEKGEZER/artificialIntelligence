{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-09T11:44:49.493287Z",
     "start_time": "2025-05-09T11:44:42.989938Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from pathlib import Path\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import grpc\n",
    "import zemberek_grpc.morphology_pb2 as z_morphology\n",
    "import zemberek_grpc.morphology_pb2_grpc as z_morphology_g\n",
    "from functools import lru_cache\n",
    "\n",
    "# Gerekli NLTK bileşenleri\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Zemberek GRPC bağlantısı\n",
    "channel = grpc.insecure_channel('localhost:6789')\n",
    "morphology_stub = z_morphology_g.MorphologyServiceStub(channel)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Melek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:44:53.477178Z",
     "start_time": "2025-05-09T11:44:51.305017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy, scipy, gensim\n",
    "print(numpy.__version__, scipy.__version__, gensim.__version__)"
   ],
   "id": "1bf401414dc7bc62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4 1.13.1 4.3.3\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:44:56.672266Z",
     "start_time": "2025-05-09T11:44:56.664269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Önbellekli kök bulma fonksiyonu\n",
    "@lru_cache(maxsize=10000)\n",
    "def get_stem(word):\n",
    "    try:\n",
    "        response = morphology_stub.AnalyzeWord(z_morphology.WordAnalysisRequest(input=word))\n",
    "        if response.analyses:\n",
    "            return response.analyses[0].lemmas[0]  # İlk lemma\n",
    "        return word\n",
    "    except grpc.RpcError as e:\n",
    "        print(f\"Zemberek hatası: {e}\")\n",
    "        return word\n",
    "\n",
    "\n",
    "# Türkçe için stopword'ler\n",
    "stop_words = set(stopwords.words(\"turkish\"))"
   ],
   "id": "6cc6ad8c5b450971",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:45:40.378508Z",
     "start_time": "2025-05-09T11:45:40.250847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Veri setini yükle\n",
    "data_path = Path(r\"C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\tum_filmler_etiketli_stemmed.csv\")\n",
    "df = pd.read_csv(data_path, encoding='utf-8-sig')\n",
    "\n",
    "# Boş olmayan cümleleri filtrele\n",
    "df = df[df['Processed_Sentence'].notna() & (df['Processed_Sentence'] != '')]\n",
    "\n",
    "print(\"Başlangıç veri seti boyutu:\", len(df))\n",
    "print(\"Sınıf dağılımı:\\n\", df['Etiket'].value_counts())\n",
    "\n"
   ],
   "id": "33225c5812dce95e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Başlangıç veri seti boyutu: 74765\n",
      "Sınıf dağılımı:\n",
      " Etiket\n",
      "komedi         6384\n",
      "suç            6251\n",
      "spor           5728\n",
      "romantik       5482\n",
      "fantastik      5166\n",
      "müzik          5088\n",
      "animasyon      4910\n",
      "gerilim        4906\n",
      "dram           4680\n",
      "tarih          4357\n",
      "bilim kurgu    4277\n",
      "aksiyon        4004\n",
      "polisiye       3819\n",
      "korku          3682\n",
      "distoptik      3439\n",
      "savaş          2592\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:45:54.323293Z",
     "start_time": "2025-05-09T11:45:54.316292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Metin ön işleme fonksiyonu (Zemberek entegrasyonlu)\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\sğüşıöçĞÜŞİÖÇ]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    words = text.split()\n",
    "    words = [get_stem(word) for word in words if word not in stop_words]\n",
    "\n",
    "    return \" \".join(words)"
   ],
   "id": "2ed8c61d8988201",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:46:32.390986Z",
     "start_time": "2025-05-09T11:45:56.840478Z"
    }
   },
   "cell_type": "code",
   "source": "df['Processed_Text'] = df['Processed_Sentence'].apply(preprocess_text)",
   "id": "15c40136752d399a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:46:38.514342Z",
     "start_time": "2025-05-09T11:46:35.250498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# İyileştirilmiş Overlap'li chunklama + akıllı etiketleme\n",
    "chunk_size = 25  # Biraz artırıldı, daha bütünsel bilgi için\n",
    "stride = 12  # Daha fazla örtüşme, veri çeşitliliği için\n",
    "chunked_texts = []\n",
    "\n",
    "for film, group in df.groupby('Film_Name'):\n",
    "    sentences = group['Processed_Text'].tolist()\n",
    "    labels = group['Etiket'].tolist()\n",
    "\n",
    "    for i in range(0, len(sentences) - chunk_size + 1, stride):\n",
    "        chunk = sentences[i:i + chunk_size]\n",
    "        chunk_labels = labels[i:i + chunk_size]\n",
    "        \n",
    "        # Etiket dağılımını hesapla\n",
    "        label_counts = pd.Series(chunk_labels).value_counts()\n",
    "        \n",
    "        # Chunk'ın en az %70'i aynı etikete sahipse o etiketi kullan\n",
    "        majority_label = label_counts.index[0]\n",
    "        majority_pct = label_counts.iloc[0] / len(chunk_labels)\n",
    "        \n",
    "        if majority_pct >= 0.7:\n",
    "            chunk_label = majority_label\n",
    "        else:\n",
    "            # Aksi takdirde mod kullan\n",
    "            chunk_label = pd.Series(chunk_labels).mode().iloc[0]\n",
    "\n",
    "        chunked_texts.append({\n",
    "            'Film_Name': film,\n",
    "            'Etiket': chunk_label,\n",
    "            'Text': ' '.join(chunk)\n",
    "        })\n",
    "\n",
    "chunked_df = pd.DataFrame(chunked_texts)"
   ],
   "id": "b66aaf4021a25d83",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:47:14.327206Z",
     "start_time": "2025-05-09T11:47:14.303238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    chunked_df['Text'],\n",
    "    chunked_df['Etiket'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=chunked_df['Etiket']\n",
    ")\n",
    "\n",
    "print(f\"Oluşturulan chunk sayısı: {len(chunked_df)}\")\n",
    "print(f\"Eğitim seti boyutu: {len(X_train)}\")\n",
    "print(f\"Test seti boyutu: {len(X_test)}\")"
   ],
   "id": "91cf06854245667d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oluşturulan chunk sayısı: 6158\n",
      "Eğitim seti boyutu: 4926\n",
      "Test seti boyutu: 1232\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:47:25.786926Z",
     "start_time": "2025-05-09T11:47:25.779942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# İnce ayarlı optimum pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        min_df=6,         # Biraz daha spesifik olması için artırıldı\n",
    "        max_df=0.65,      # Orta seviye ayar\n",
    "        ngram_range=(1, 3),  # 1-3 gram - daha iyi dil örüntüleri\n",
    "        max_features=5000,  # Biraz artırıldı \n",
    "        sublinear_tf=True   # Logaritmik TF skalama\n",
    "    )),\n",
    "    ('clf', LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        max_iter=10000,\n",
    "        solver='saga',     # Büyük veri setleri için en iyi\n",
    "        penalty='elasticnet', # Hem L1 hem L2 regularizasyonu  \n",
    "        l1_ratio=0.15,     # Daha hafif L1 - daha az özellik elemesi\n",
    "        C=0.25            # Biraz daha yüksek - gerekli örüntüleri öğrenmek için\n",
    "    ))\n",
    "])"
   ],
   "id": "6668e354d6b843e9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:47:28.408136Z",
     "start_time": "2025-05-09T11:47:28.403026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# İnce ayarlı parametre gridleri\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [4500, 5000, 5500],\n",
    "    'clf__C': [0.2, 0.25, 0.3],\n",
    "    'clf__l1_ratio': [0.1, 0.15, 0.2]\n",
    "}"
   ],
   "id": "4aaf14370a952751",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:47:31.037046Z",
     "start_time": "2025-05-09T11:47:31.030080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# K-fold cross-validation ile model eğitimi\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=cv, verbose=1, n_jobs=-1, \n",
    "                          scoring='f1_weighted')"
   ],
   "id": "5fe4d263db533ae5",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:50:49.393523Z",
     "start_time": "2025-05-09T11:47:36.230405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Model eğitiliyor...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# En iyi parametreleri göster\n",
    "print(\"\\nEn iyi hiperparametreler:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"En iyi cross-validation skoru: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# En iyi modeli al\n",
    "best_model = grid_search.best_estimator_\n"
   ],
   "id": "8f4e973bdf824294",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model eğitiliyor...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "\n",
      "En iyi hiperparametreler:\n",
      "{'clf__C': 0.3, 'clf__l1_ratio': 0.1, 'tfidf__max_features': 5500}\n",
      "En iyi cross-validation skoru: 0.9024\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:51:05.046920Z",
     "start_time": "2025-05-09T11:51:01.615464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Değerlendirme\n",
    "# Test verisi üzerinde tahmin\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Eğitim verisi üzerinde tahmin (overfitting kontrolü için)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Eğitim Verisi Performansı:\")\n",
    "print(f\"Eğitim Doğruluğu (Train Accuracy): {train_accuracy:.4f}\")\n",
    "print(\"\\nEğitim Verisi Sınıflandırma Raporu:\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Test Verisi Performansı:\")\n",
    "print(f\"Test Doğruluğu (Test Accuracy): {test_accuracy:.4f}\")\n",
    "print(\"\\nTest Verisi Sınıflandırma Raporu:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Overfitting analizi\n",
    "train_test_diff = train_accuracy - test_accuracy\n",
    "print(f\"ℹ️ Bilgi: Eğitim-Test farkı: {train_test_diff:.4f}\")\n",
    "\n",
    "if train_accuracy > 0.95 and train_test_diff > 0.2:\n",
    "    print(\"⚠️ UYARI: Model aşırı öğrenme (overfitting) yapmış görünüyor!\")\n",
    "elif train_test_diff < 0.08:\n",
    "    print(\"✅ Model iyi genelleme yapıyor gibi görünüyor\")\n",
    "else:\n",
    "    print(\"ℹ️ Modelde hafif overfitting olabilir\")\n",
    "\n",
    "# Sınıf bazlı performans analizi\n",
    "test_report = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "class_f1 = {cls: scores['f1-score'] for cls, scores in test_report.items() \n",
    "          if cls not in ['accuracy', 'macro avg', 'weighted avg']}\n",
    "\n",
    "# En kötü 3 sınıfı bul\n",
    "worst_classes = sorted(class_f1.items(), key=lambda x: x[1])[:3]\n",
    "print(\"\\nEn Düşük Performans Gösteren Sınıflar:\")\n",
    "for cls, score in worst_classes:\n",
    "    print(f\"{cls}: F1-score = {score:.4f}\")\n",
    "\n",
    "# En iyi 3 sınıfı bul\n",
    "best_classes = sorted(class_f1.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "print(\"\\nEn Yüksek Performans Gösteren Sınıflar:\")\n",
    "for cls, score in best_classes:\n",
    "    print(f\"{cls}: F1-score = {score:.4f}\")\n",
    "\n",
    "# Karışıklık matrisi analizi\n",
    "print(\"\\nKarışıklık matrisini hesaplama ve görselleştirme...\")\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Yalnızca en çok karıştırılan sınıfları göster\n",
    "    misclassification = []\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(classes)):\n",
    "            if i != j and cm[i, j] > 0:\n",
    "                misclassification.append((classes[i], classes[j], cm[i, j], cm_norm[i, j]))\n",
    "    \n",
    "    # En çok karıştırılan 10 sınıf çifti\n",
    "    top_conf = sorted(misclassification, key=lambda x: x[2], reverse=True)[:10]\n",
    "    \n",
    "    print(\"\\nEn Çok Karıştırılan Sınıflar:\")\n",
    "    for true_cls, pred_cls, count, pct in top_conf:\n",
    "        print(f\"Gerçek: {true_cls}, Tahmin: {pred_cls} - {count} örnek ({pct:.2%})\")\n",
    "\n",
    "# Karışıklık matrisi analizi yap\n",
    "plot_confusion_matrix(y_test, y_pred_test, sorted(chunked_df['Etiket'].unique()))\n",
    "\n",
    "# TF-IDF vektörleyicisinden en önemli kelimeler\n",
    "def get_top_features_per_class(vectorizer, clf, class_labels, top_n=10):\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    if hasattr(clf, 'coef_'):\n",
    "        coefs = clf.coef_\n",
    "    else:\n",
    "        raise ValueError(\"Sınıflandırıcının coef_ özelliği yok\")\n",
    "    \n",
    "    top_features = {}\n",
    "    \n",
    "    for i, class_name in enumerate(class_labels):\n",
    "        # Bu sınıf için katsayıları al\n",
    "        class_coefs = coefs[i]\n",
    "        # En yüksek katsayılara sahip özelliklerin indislerini bul\n",
    "        top_indices = np.argsort(class_coefs)[-top_n:]\n",
    "        # Bu indislere karşılık gelen özellik isimlerini ve katsayılarını al\n",
    "        top_features[class_name] = [(feature_names[idx], class_coefs[idx]) for idx in top_indices]\n",
    "    \n",
    "    return top_features\n",
    "\n",
    "# Her sınıf için en ayırt edici kelimeleri alma\n",
    "print(\"\\nEn Ayırt Edici Kelimeler (Her Film Türü İçin):\")\n",
    "class_labels = best_model.named_steps['clf'].classes_\n",
    "vectorizer = best_model.named_steps['tfidf']\n",
    "classifier = best_model.named_steps['clf']\n",
    "\n",
    "try:\n",
    "    top_features = get_top_features_per_class(vectorizer, classifier, class_labels)\n",
    "    \n",
    "    for class_name, features in top_features.items():\n",
    "        print(f\"\\n{class_name.upper()} türü için en ayırt edici kelimeler:\")\n",
    "        for feature, coef in sorted(features, key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  - {feature}: {coef:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Özellik analizi sırasında hata: {e}\")\n",
    "\n",
    "# Final model performans özeti\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL MODEL PERFORMANS ÖZETİ\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Eğitim Doğruluğu: {train_accuracy:.4f}\")\n",
    "print(f\"Test Doğruluğu: {test_accuracy:.4f}\")\n",
    "print(f\"Eğitim-Test Farkı: {train_test_diff:.4f}\")\n",
    "print(f\"Ağırlıklı F1-Score: {test_report['weighted avg']['f1-score']:.4f}\")\n",
    "print(\"=\"*50)\n"
   ],
   "id": "33e99c1d8b08b8b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Eğitim Verisi Performansı:\n",
      "Eğitim Doğruluğu (Train Accuracy): 0.9584\n",
      "\n",
      "Eğitim Verisi Sınıflandırma Raporu:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     aksiyon       0.98      0.97      0.98       263\n",
      "   animasyon       0.98      0.98      0.98       323\n",
      " bilim kurgu       0.96      0.99      0.97       282\n",
      "   distoptik       0.94      0.97      0.95       226\n",
      "        dram       0.99      0.94      0.97       309\n",
      "   fantastik       0.98      0.96      0.97       340\n",
      "     gerilim       0.97      0.94      0.95       323\n",
      "      komedi       0.96      0.95      0.95       422\n",
      "       korku       0.90      0.98      0.94       243\n",
      "       müzik       0.90      0.98      0.94       336\n",
      "    polisiye       0.97      0.96      0.97       250\n",
      "    romantik       0.96      0.91      0.93       362\n",
      "       savaş       0.90      1.00      0.95       170\n",
      "        spor       0.99      0.96      0.97       378\n",
      "         suç       0.94      0.94      0.94       413\n",
      "       tarih       0.99      0.95      0.97       286\n",
      "\n",
      "    accuracy                           0.96      4926\n",
      "   macro avg       0.96      0.96      0.96      4926\n",
      "weighted avg       0.96      0.96      0.96      4926\n",
      "\n",
      "\n",
      "==================================================\n",
      "Test Verisi Performansı:\n",
      "Test Doğruluğu (Test Accuracy): 0.9221\n",
      "\n",
      "Test Verisi Sınıflandırma Raporu:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     aksiyon       0.98      0.95      0.97        66\n",
      "   animasyon       0.99      0.99      0.99        81\n",
      " bilim kurgu       0.95      1.00      0.97        71\n",
      "   distoptik       0.85      0.93      0.89        56\n",
      "        dram       1.00      0.86      0.92        77\n",
      "   fantastik       0.96      0.94      0.95        85\n",
      "     gerilim       0.88      0.95      0.91        81\n",
      "      komedi       0.90      0.85      0.87       106\n",
      "       korku       0.88      0.95      0.91        60\n",
      "       müzik       0.82      0.94      0.88        84\n",
      "    polisiye       0.94      0.95      0.94        63\n",
      "    romantik       0.92      0.79      0.85        90\n",
      "       savaş       0.89      0.98      0.93        42\n",
      "        spor       1.00      0.93      0.96        95\n",
      "         suç       0.86      0.94      0.90       103\n",
      "       tarih       0.98      0.89      0.93        72\n",
      "\n",
      "    accuracy                           0.92      1232\n",
      "   macro avg       0.93      0.93      0.92      1232\n",
      "weighted avg       0.93      0.92      0.92      1232\n",
      "\n",
      "==================================================\n",
      "\n",
      "ℹ️ Bilgi: Eğitim-Test farkı: 0.0363\n",
      "✅ Model iyi genelleme yapıyor gibi görünüyor\n",
      "\n",
      "En Düşük Performans Gösteren Sınıflar:\n",
      "romantik: F1-score = 0.8503\n",
      "komedi: F1-score = 0.8738\n",
      "müzik: F1-score = 0.8778\n",
      "\n",
      "En Yüksek Performans Gösteren Sınıflar:\n",
      "animasyon: F1-score = 0.9877\n",
      "bilim kurgu: F1-score = 0.9726\n",
      "aksiyon: F1-score = 0.9692\n",
      "\n",
      "Karışıklık matrisini hesaplama ve görselleştirme...\n",
      "\n",
      "En Çok Karıştırılan Sınıflar:\n",
      "Gerçek: romantik, Tahmin: müzik - 8 örnek (8.89%)\n",
      "Gerçek: komedi, Tahmin: müzik - 5 örnek (4.72%)\n",
      "Gerçek: dram, Tahmin: gerilim - 4 örnek (5.19%)\n",
      "Gerçek: komedi, Tahmin: suç - 4 örnek (3.77%)\n",
      "Gerçek: romantik, Tahmin: distoptik - 4 örnek (4.44%)\n",
      "Gerçek: komedi, Tahmin: romantik - 3 örnek (2.83%)\n",
      "Gerçek: spor, Tahmin: komedi - 3 örnek (3.16%)\n",
      "Gerçek: tarih, Tahmin: savaş - 3 örnek (4.17%)\n",
      "Gerçek: dram, Tahmin: müzik - 2 örnek (2.60%)\n",
      "Gerçek: dram, Tahmin: suç - 2 örnek (2.60%)\n",
      "\n",
      "En Ayırt Edici Kelimeler (Her Film Türü İçin):\n",
      "\n",
      "AKSIYON türü için en ayırt edici kelimeler:\n",
      "  - neo: 1.8930\n",
      "  - tır: 1.5193\n",
      "  - hans: 1.4456\n",
      "  - john: 1.4418\n",
      "  - mac: 1.3712\n",
      "  - mac klein: 1.2857\n",
      "  - klein: 1.2857\n",
      "  - powell: 1.2816\n",
      "  - terörist: 1.2529\n",
      "  - rehin: 1.2285\n",
      "\n",
      "ANIMASYON türü için en ayırt edici kelimeler:\n",
      "  - riley: 3.2102\n",
      "  - woody: 3.0402\n",
      "  - buzz: 2.3671\n",
      "  - elsa: 2.1378\n",
      "  - anna: 2.0796\n",
      "  - nes: 1.7070\n",
      "  - sey: 1.6805\n",
      "  - oyuncak: 1.5446\n",
      "  - hayir: 1.4616\n",
      "  - olamaz: 1.3977\n",
      "\n",
      "BILIM KURGU türü için en ayırt edici kelimeler:\n",
      "  - murph: 2.8368\n",
      "  - cooper: 2.8132\n",
      "  - rüya: 2.5833\n",
      "  - fischer: 2.4478\n",
      "  - cobb: 2.3388\n",
      "  - brand: 1.7405\n",
      "  - tars: 1.4686\n",
      "  - fikir: 1.3753\n",
      "  - zihin: 1.3457\n",
      "  - bilinçaltı: 1.3455\n",
      "\n",
      "DISTOPTIK türü için en ayırt edici kelimeler:\n",
      "  - kee: 2.4961\n",
      "  - theo: 2.2682\n",
      "  - julia: 1.8208\n",
      "  - bebek: 1.6536\n",
      "  - gerçek: 1.0271\n",
      "  - syd: 1.0120\n",
      "  - hadi: 1.0034\n",
      "  - wallace: 0.9629\n",
      "  - marichka: 0.9450\n",
      "  - dünya: 0.9382\n",
      "\n",
      "DRAM türü için en ayırt edici kelimeler:\n",
      "  - forrest: 3.3462\n",
      "  - andy: 2.2685\n",
      "  - gump: 2.0046\n",
      "  - jenny: 1.7687\n",
      "  - goldfarb: 1.4990\n",
      "  - teğmen dan: 1.4432\n",
      "  - karides: 1.3679\n",
      "  - teğmen: 1.1730\n",
      "  - sar: 1.1719\n",
      "  - dufresne: 1.1125\n",
      "\n",
      "FANTASTIK türü için en ayırt edici kelimeler:\n",
      "  - tristan: 2.1680\n",
      "  - harry: 2.1217\n",
      "  - frodo: 2.0449\n",
      "  - potter: 1.7315\n",
      "  - yıldız: 1.5540\n",
      "  - efendi: 1.3597\n",
      "  - kral: 1.2656\n",
      "  - bay frodo: 1.2106\n",
      "  - duvar: 1.2082\n",
      "  - büyücü: 1.1799\n",
      "\n",
      "GERILIM türü için en ayırt edici kelimeler:\n",
      "  - harry: 2.1357\n",
      "  - hasta: 1.8028\n",
      "  - rachel: 1.6675\n",
      "  - laeddis: 1.4676\n",
      "  - patron: 1.4329\n",
      "  - dover: 1.3272\n",
      "  - alex: 1.2870\n",
      "  - anna: 1.2650\n",
      "  - koğuş: 1.1876\n",
      "  - caul: 1.1770\n",
      "\n",
      "KOMEDI türü için en ayırt edici kelimeler:\n",
      "  - ron: 2.6961\n",
      "  - chow: 2.4584\n",
      "  - lan: 2.2119\n",
      "  - sik: 1.9669\n",
      "  - burgundy: 1.9013\n",
      "  - abi: 1.8700\n",
      "  - evan: 1.6547\n",
      "  - mclovin: 1.5564\n",
      "  - seth: 1.5519\n",
      "  - haber: 1.4848\n",
      "\n",
      "KORKU türü için en ayırt edici kelimeler:\n",
      "  - peter: 2.0426\n",
      "  - peder: 2.0365\n",
      "  - annie: 1.7950\n",
      "  - charlie: 1.5810\n",
      "  - carolyn: 1.5324\n",
      "  - nancy: 1.4893\n",
      "  - anne: 1.4352\n",
      "  - lorraine: 1.4304\n",
      "  - april: 1.3553\n",
      "  - od: 1.2333\n",
      "\n",
      "MÜZIK türü için en ayırt edici kelimeler:\n",
      "  - freddie: 3.3825\n",
      "  - şark: 2.5907\n",
      "  - jack: 1.8657\n",
      "  - çal: 1.7670\n",
      "  - sahne: 1.4121\n",
      "  - ally: 1.3176\n",
      "  - grup: 1.2948\n",
      "  - albüm: 1.2878\n",
      "  - konser: 1.2436\n",
      "  - queen: 1.1631\n",
      "\n",
      "POLISIYE türü için en ayırt edici kelimeler:\n",
      "  - clarice: 2.5718\n",
      "  - starling: 2.2136\n",
      "  - lecter: 2.0211\n",
      "  - dedektif: 1.4725\n",
      "  - cinayet: 1.4273\n",
      "  - crawford: 1.0330\n",
      "  - pislik: 1.0218\n",
      "  - kahret: 1.0057\n",
      "  - buffalo: 0.9834\n",
      "  - buffalo bill: 0.9834\n",
      "\n",
      "ROMANTIK türü için en ayırt edici kelimeler:\n",
      "  - rose: 2.9942\n",
      "  - bay: 2.1253\n",
      "  - jack: 2.0980\n",
      "  - bayan: 1.6976\n",
      "  - darcy: 1.5979\n",
      "  - sandal: 1.5079\n",
      "  - mia: 1.5031\n",
      "  - bay darcy: 1.4174\n",
      "  - ge: 1.3608\n",
      "  - bingley: 1.2673\n",
      "\n",
      "SAVAŞ türü için en ayırt edici kelimeler:\n",
      "  - wadek: 2.5644\n",
      "  - yahudi: 2.5130\n",
      "  - şaban: 2.0997\n",
      "  - szpilman: 2.0307\n",
      "  - palyaço: 1.9240\n",
      "  - efendim: 1.6422\n",
      "  - alman: 1.5344\n",
      "  - tüfek: 1.4941\n",
      "  - kuvvet: 1.4011\n",
      "  - kovboy: 1.2844\n",
      "\n",
      "SPOR türü için en ayırt edici kelimeler:\n",
      "  - dövüş: 3.0005\n",
      "  - micky: 2.5140\n",
      "  - dicky: 2.2676\n",
      "  - yarış: 2.0403\n",
      "  - hey: 1.9720\n",
      "  - mick: 1.8365\n",
      "  - niki: 1.8203\n",
      "  - maç: 1.8127\n",
      "  - rocky: 1.8041\n",
      "  - değii: 1.7813\n",
      "\n",
      "SUÇ türü için en ayırt edici kelimeler:\n",
      "  - jimmy: 2.4094\n",
      "  - henry: 1.9670\n",
      "  - paulie: 1.6178\n",
      "  - kare: 1.5786\n",
      "  - leon: 1.4566\n",
      "  - michael: 1.4339\n",
      "  - par: 1.3745\n",
      "  - corleone: 1.3367\n",
      "  - mathilda: 1.1125\n",
      "  - tommy: 1.1046\n",
      "\n",
      "TARIH türü için en ayırt edici kelimeler:\n",
      "  - yüzbaşı: 2.3332\n",
      "  - ryan: 2.1021\n",
      "  - efendim: 1.9634\n",
      "  - komuta: 1.7961\n",
      "  - logue: 1.5808\n",
      "  - upham: 1.5545\n",
      "  - bertie: 1.5456\n",
      "  - kral: 1.5275\n",
      "  - reiben: 1.3269\n",
      "  - majeste: 1.1822\n",
      "\n",
      "==================================================\n",
      "FINAL MODEL PERFORMANS ÖZETİ\n",
      "==================================================\n",
      "Eğitim Doğruluğu: 0.9584\n",
      "Test Doğruluğu: 0.9221\n",
      "Eğitim-Test Farkı: 0.0363\n",
      "Ağırlıklı F1-Score: 0.9221\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:53:57.705348Z",
     "start_time": "2025-05-09T11:53:56.095087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Model kaydetme\n",
    "# Modeli kaydet\n",
    "model_path = Path(r\"C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\Models\\tam_veri_seti_model4.pkl\")\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"Model kaydedildi: {model_path}\")"
   ],
   "id": "1ccde896989c8fa0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\Models\\tam_veri_seti_model4.pkl\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
