{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:08:12.511982Z",
     "start_time": "2025-05-09T11:07:59.273369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import grpc\n",
    "import zemberek_grpc.morphology_pb2 as z_morphology\n",
    "import zemberek_grpc.morphology_pb2_grpc as z_morphology_g\n",
    "channel = grpc.insecure_channel('localhost:6789')\n",
    "morphology_stub = z_morphology_g.MorphologyServiceStub(channel)\n",
    "# Özel Türkçe stopwords listesi (NLTK'ya ek olarak)\n",
    "extended_turkish_stopwords = {\n",
    "    'a', 'acaba', 'acep', 'adamakıllı', 'adeta', 'ait', 'altmış', 'altı',\n",
    "    'ama', 'amma', 'anca', 'ancak', 'arada', 'artık', 'aslında', 'aynen', 'ayrıca',\n",
    "    'az', 'açıkça', 'açıkçası', 'bana', 'bari', 'bazen', 'bazı', 'başkası',\n",
    "     'belki', 'ben', 'benden', 'beni', 'benim', 'beri', 'beriki', 'beş',\n",
    "     'bilcümle', 'bile', 'bin', 'binaen', 'binaenaleyh', 'bir', 'biraz',\n",
    "    'birazdan', 'birbiri', 'birden', 'birdenbire', 'biri', 'birice', 'birileri',\n",
    "    'birisi', 'birkaç', 'birkaçı', 'birkez', 'birlikte', 'birçok', 'birçoğu',\n",
    "    'bir şey', 'bir şeyi', 'birşey', 'birşeyi', 'bitevi', 'biteviye',\n",
    "    'bittabi', 'biz', 'bizatihi', 'bizce', 'bizcileyin', 'bizden', 'bize', 'bizi',\n",
    "    'bizim', 'bizimki', 'bizzat', 'boşuna', 'bu', 'buna', 'bunda', 'bundan',\n",
    "    'bunlar', 'bunları', 'bunların', 'bunu', 'bunun', 'buracıkta', 'burada',\n",
    "    'buradan', 'burası', 'böyle', 'böylece', 'böylecene', 'böylelikle',\n",
    "    'böylemesine', 'böylesine', 'büsbütün', 'bütün', 'cuk', 'cümlesi', 'da',\n",
    "    'daha', 'dahi', 'dahil', 'dahilen', 'daima', 'dair', 'dayanarak', 'de', 'defa',\n",
    "    'dek', 'demin', 'demincek', 'deminden', 'denli', 'derakap', 'derhal', 'derken',\n",
    "     'değil', 'değin', 'diye', 'diğer', 'diğeri', 'doksan', 'dokuz',\n",
    "    'dolayı', 'dolayısıyla', 'doğru', 'dört', 'edecek', 'eden', 'ederek', 'edilecek',\n",
    "    'ediliyor', 'edilmesi', 'ediyor', 'elbet', 'elbette', 'elli', 'emme', 'en',\n",
    "    'enikonu', 'epey', 'epeyce', 'epeyi', 'esasen', 'esnasında', 'etmesi', 'etraflı',\n",
    "    'etraflıca', 'etti', 'ettiği', 'ettiğini', 'evleviyetle', 'evvel', 'evvela',\n",
    "    'evvelce', 'evvelden', 'evvelemirde', 'evveli', 'eđer', 'eğer', 'fakat',\n",
    "    'filanca', 'gah', 'gayet', 'gayetle', 'gayri', 'gayrı', 'gelgelelim', 'gene',\n",
    "    'gerek', 'gerçi', 'geçende', 'geçenlerde', 'gibi', 'gibilerden', 'gibisinden',\n",
    "    'gine', 'göre', 'gırla', 'hakeza', 'halbuki', 'halen', 'halihazırda', 'haliyle',\n",
    "    'handiyse', 'hangi', 'hangisi', 'hani', 'hariç', 'hasebiyle', 'hasılı', 'hatta',\n",
    "    'hele', 'hem', 'henüz', 'hep', 'hepsi', 'her', 'herhangi', 'herkes', 'herkesin',\n",
    "    'hiç', 'hiçbir', 'hiçbiri', 'hoş', 'hulasaten', 'iken', 'iki', 'ila', 'ile',\n",
    "    'ilen', 'ilgili', 'ilk', 'illa', 'illaki', 'imdi', 'indinde', 'inen', 'insermi',\n",
    "    'ise', 'ister', 'itibaren', 'itibariyle', 'itibarıyla', 'iyi', 'iyice', 'iyicene',\n",
    "    'için', 'iş', 'işte', 'kadar', 'kaffesi', 'kah', 'kala', 'kannımca',\n",
    "    'karşın', 'katrilyon', 'kaynak', 'kaçı', 'kelli', 'kendi', 'kendilerine',\n",
    "    'kendini', 'kendisi', 'kendisine', 'kendisini', 'kere', 'kez', 'keza',\n",
    "    'kezalik', 'keşke', 'keţke', 'ki', 'kim', 'kimden', 'kime', 'kimi', 'kimisi',\n",
    "    'kimse', 'kimsecik', 'kimsecikler', 'külliyen', 'kırk',\n",
    "    'kısaca', 'lakin', 'leh', 'lütfen', 'maada', 'madem', 'mademki', 'mamafih',\n",
    "    'mebni',  'meğer', 'meğerki', 'meğerse', 'milyar', 'milyon', 'mu',\n",
    "    'mü', 'mi', 'mı',  'nasıl', 'nasılsa', 'nazaran', 'naşi', 'ne', 'neden',\n",
    "    'nedeniyle', 'nedenle', 'nedense', 'nerde', 'nerden', 'nerdeyse', 'nere',\n",
    "    'nerede', 'nereden', 'neredeyse', 'neresi', 'nereye', 'netekim', 'neye', 'neyi',\n",
    "    'neyse', 'nice', 'nihayet', 'nihayetinde', 'nitekim', 'niye', 'niçin', 'o',\n",
    "    'olan', 'olarak', 'oldu', 'olduklarını', 'oldukça', 'olduğu', 'olduğunu',\n",
    "    'olmadı', 'olmadığı', 'olmak', 'olması', 'olmayan', 'olmaz', 'olsa', 'olsun',\n",
    "    'olup', 'olur', 'olursa', 'oluyor', 'on', 'ona', 'onca', 'onculayın', 'onda',\n",
    "    'ondan', 'onlar', 'onlardan', 'onları', 'onların', 'onu',\n",
    "    'onun', 'oracık', 'oracıkta', 'orada', 'oradan', 'oranca', 'oranla', 'oraya',\n",
    "    'otuz', 'oysa', 'oysaki', 'pek', 'pekala', 'peki', 'pekçe', 'peyderpey', 'rağmen',\n",
    "    'sadece', 'sahi', 'sahiden', 'sana', 'sanki', 'sekiz', 'seksen', 'sen', 'senden',\n",
    "    'seni', 'senin', 'siz', 'sizden', 'sizi', 'sizin', 'sonra', 'sonradan',\n",
    "    'sonraları', 'sonunda', 'tabii', 'tam', 'tamam', 'tamamen', 'tamamıyla',\n",
    "    'tarafından', 'tek', 'trilyon', 'tüm', 'var', 'vardı', 'vasıtasıyla', 've',\n",
    "    'velev', 'velhasıl', 'velhasılıkelam', 'veya', 'veyahut', 'ya', 'yahut',\n",
    "    'yakinen', 'yakında', 'yakından', 'yakınlarda', 'yalnız', 'yalnızca', 'yani',\n",
    "    'yapacak', 'yapmak', 'yaptı', 'yaptıkları', 'yaptığı', 'yaptığını', 'yapılan',\n",
    "    'yapılması', 'yapıyor', 'yedi', 'yeniden', 'yenilerde', 'yerine',\n",
    "    'yetmiş', 'yine', 'yirmi', 'yok', 'yoksa', 'yoluyla', 'yüz', 'yüzünden',\n",
    "    'zarfında', 'zaten', 'zati', 'zira', 'çabuk', 'çabukça', 'çeşitli', 'çok',\n",
    "    'çokları', 'çoklarınca', 'çokluk', 'çoklukla', 'çokça', 'çoğu', 'çoğun',\n",
    "    'çoğunca', 'çoğunlukla', 'çünkü', 'öbür', 'öbürkü', 'öbürü', 'önce', 'önceden',\n",
    "    'önceleri', 'öncelikle', 'öteki', 'ötekisi', 'öyle', 'öylece', 'öylelikle',\n",
    "    'öylemesine', 'öz', 'üzere', 'üç',  'şayet', 'şey', 'şeyden', 'şeyi', 'şeyler',\n",
    "    'şu', 'şuna', 'şuncacık', 'şunda', 'şundan', 'şunlar', 'şunları', 'şunu',\n",
    "    'şunun', 'şura', 'şuracık', 'şuracıkta', 'şurası', 'şöyle',  'şimdi', 'şöyle'\n",
    "}\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "turkish_stopwords = set(stopwords.words('turkish'))\n",
    "\n",
    "# Tüm stopwords'leri birleştir\n",
    "all_stopwords = turkish_stopwords.union(extended_turkish_stopwords)"
   ],
   "id": "91a48e4c56091fea",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Melek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Melek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:08:14.943354Z",
     "start_time": "2025-05-09T11:08:14.933502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lemma ve Kök bulma fonksiyonları\n",
    "def get_lemmas(word):\n",
    "    \"\"\"Bir kelimenin lemmalarını (köklerini) Zemberek ile bulur\"\"\"\n",
    "    try:\n",
    "        response = morphology_stub.AnalyzeWord(z_morphology.WordAnalysisRequest(input=word))\n",
    "        if response.analyses:\n",
    "            return response.analyses[0].lemmas\n",
    "        return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def get_stem(word):\n",
    "    \"\"\"Bir kelimenin kökünü Zemberek ile bulur\"\"\"\n",
    "    lemmas = get_lemmas(word)\n",
    "    return lemmas[0] if lemmas else word\n"
   ],
   "id": "b31441ecf1b2509e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:08:16.816577Z",
     "start_time": "2025-05-09T11:08:16.807051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Çoklu kelimeler için toplu kök bulma (performans iyileştirmesi)\n",
    "def get_stems_batch(words):\n",
    "    \"\"\"Kelime listesi için kök bulma işlemini toplu yapar\"\"\"\n",
    "    results = {}\n",
    "    for word in words:\n",
    "        if word not in results:\n",
    "            results[word] = get_stem(word)\n",
    "    return results"
   ],
   "id": "5373ab6bd14e3023",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:08:21.193508Z",
     "start_time": "2025-05-09T11:08:21.183506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_srt_file(file_path):\n",
    "    \"\"\"SRT dosyasını temizler (zaman damgalarını ve numaraları kaldırır)\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    cleaned_lines = []\n",
    "    current_line = \"\"\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        # Zaman damgası satırlarını ve numaralandırmayı atla\n",
    "        if re.match(r'^\\d+$', line) or '-->' in line:\n",
    "            continue\n",
    "        # Boş satırları atla\n",
    "        if not line:\n",
    "            if current_line:  # Eğer biriktirilen bir satır varsa ekle\n",
    "                cleaned_lines.append(current_line)\n",
    "                current_line = \"\"\n",
    "            continue\n",
    "        \n",
    "        # Satırları birleştir (altyazılarda cümleler genelde birden fazla satıra bölünebilir)\n",
    "        if current_line:\n",
    "            current_line += \" \" + line\n",
    "        else:\n",
    "            current_line = line\n",
    "    \n",
    "    # Son satırı eklemeyi unutma\n",
    "    if current_line:\n",
    "        cleaned_lines.append(current_line)\n",
    "        \n",
    "    return cleaned_lines"
   ],
   "id": "148ca7d4c84db449",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:08:23.519033Z",
     "start_time": "2025-05-09T11:08:23.512034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "\n",
    "def split_into_sentences(lines):\n",
    "    \"\"\"Metni cümlelere böler\"\"\"\n",
    "    sentences = []\n",
    "    for line in lines:\n",
    "        # NLTK'nın sent_tokenize fonksiyonunu kullanarak daha doğru cümle bölme\n",
    "        line_sentences = sent_tokenize(line)\n",
    "        for sentence in line_sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if sentence:\n",
    "                sentences.append(sentence)\n",
    "    return sentences\n"
   ],
   "id": "39b47943c58213f0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:08:27.222511Z",
     "start_time": "2025-05-09T11:08:27.216513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_sentence(sentence):\n",
    "    \"\"\"Cümleyi temizler\"\"\"\n",
    "    # Altyazı notasyonlarını temizle ([gülüşmeler], (fısıldar) gibi)\n",
    "    sentence = re.sub(r'\\[.*?\\]|\\(.*?\\)', '', sentence)\n",
    "    \n",
    "    # HTML etiketlerini kaldır\n",
    "    sentence = re.sub(r'<.*?>', '', sentence)\n",
    "    \n",
    "    # Noktalama işaretlerini kaldır (sadece kelimeler, sayılar ve boşluklar kalsın)\n",
    "    sentence = re.sub(r'[^\\w\\sğüşıöçĞÜŞİÖÇ0-9]', ' ', sentence)\n",
    "    \n",
    "    # Küçük harfe çevir (sayılar etkilenmez)\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # Fazla boşlukları kaldır\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
    "    \n",
    "    return sentence"
   ],
   "id": "81193476644b7fe",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:08:28.965756Z",
     "start_time": "2025-05-09T11:08:28.954656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_stopwords_and_stem(sentence, stem_cache=None):\n",
    "    \"\"\"Stopwords kaldırır ve kök bulma işlemi yapar\"\"\"\n",
    "    if stem_cache is None:\n",
    "        stem_cache = {}\n",
    "        \n",
    "    words = word_tokenize(sentence)\n",
    "    processed_words = []\n",
    "    \n",
    "    # Cache'de olmayan kelimeler için kök bulma işlemi yap\n",
    "    new_words = [w for w in words if w not in stem_cache and w not in all_stopwords \n",
    "                 and (len(w) > 2 or w.isdigit() or re.match(r'^\\w+-\\d+\\.?\\d*$', w))]\n",
    "    \n",
    "    if new_words:\n",
    "        new_stems = get_stems_batch(new_words)\n",
    "        stem_cache.update(new_stems)\n",
    "    \n",
    "    # Cümledeki kelimeleri işle\n",
    "    for word in words:\n",
    "        if word not in all_stopwords and (len(word) > 2 or word.isdigit() or re.match(r'^\\w+-\\d+\\.?\\d*$', word)):\n",
    "            if not word.isdigit() and not re.match(r'^\\w+-\\d+\\.?\\d*$', word):\n",
    "                stemmed_word = stem_cache.get(word, get_stem(word))\n",
    "                processed_words.append(stemmed_word)\n",
    "            else:\n",
    "                processed_words.append(word)\n",
    "    \n",
    "    return ' '.join(processed_words)"
   ],
   "id": "4997a9571c603d6e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:08:30.981079Z",
     "start_time": "2025-05-09T11:08:30.971068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_all_files(directory):\n",
    "    \"\"\"Tüm dosyaları işler\"\"\"\n",
    "    all_data = []\n",
    "    stem_cache = {}  # Kök bulma için cache\n",
    "    \n",
    "    for file_path in directory.glob('*.srt'):\n",
    "        print(f\"İşleniyor: {file_path.name}\")\n",
    "        film_name = file_path.stem\n",
    "        \n",
    "        # 1. SRT dosyasını temizle\n",
    "        cleaned_lines = clean_srt_file(file_path)\n",
    "        \n",
    "        # 2. Cümlelere böl\n",
    "        sentences = split_into_sentences(cleaned_lines)\n",
    "        \n",
    "        # 3. Her cümleyi işle\n",
    "        for sentence in sentences:\n",
    "            # 4. Cümleyi temizle\n",
    "            cleaned_sentence = clean_sentence(sentence)\n",
    "            \n",
    "            # 5. Stopwords kaldır ve kök bulma işlemi yap\n",
    "            final_sentence = remove_stopwords_and_stem(cleaned_sentence, stem_cache)\n",
    "            \n",
    "            # Boş cümleleri atlama\n",
    "            if final_sentence.strip():\n",
    "                all_data.append({\n",
    "                    'Film_Name': film_name,\n",
    "                    'Original_Sentence': sentence,\n",
    "                    'Processed_Sentence': final_sentence\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(all_data)"
   ],
   "id": "9f8a80b8a45ec904",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:29:50.554694Z",
     "start_time": "2025-05-09T11:29:50.537493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Film etiketleri sözlüğü\n",
    "film_etiketleri = {\n",
    "    \"Titanic.srt\": \"romantik\",\n",
    "    \"The Pianist.srt\": \"savaş\",\n",
    "    \"Inception.srt\": \"bilim kurgu\",\n",
    "    \"The Matrix.srt\": \"aksiyon\",\n",
    "    \"The Shawshank Redemption.srt\": \"dram\",\n",
    "    \"The Lord Of The Rings.srt\": \"fantastik\",\n",
    "    \"Shutter Island.srt\": \"gerilim\",\n",
    "    \"Leon.srt\": \"suç\",\n",
    "    \"Saving Private Ryan.srt\": \"tarih\",\n",
    "    \"Whiplash.srt\": \"müzik\",\n",
    "    \"The Hangover.srt\": \"komedi\",\n",
    "    \"The Conjuring.srt\": \"korku\",\n",
    "    \"Frozen.srt\": \"animasyon\",\n",
    "    \"Rocky.srt\": \"spor\",\n",
    "    \"Blade Runner.srt\": \"distoptik\",\n",
    "    \"Se7en.srt\": \"polisiye\",\n",
    "    \"Pride & Prejudice.srt\": \"romantik\",\n",
    "    \"Full Metal Jacket.srt\": \"savaş\",\n",
    "    \"Interstellar.srt\": \"bilim kurgu\",\n",
    "    \"Mad Max.srt\": \"aksiyon\",\n",
    "    \"Requiem for a Dream.srt\": \"dram\",\n",
    "    \"Stardust.srt\": \"fantastik\",\n",
    "    \"Gone Girl.srt\": \"gerilim\",\n",
    "    \"Goodfellas.srt\": \"suç\",\n",
    "    \"The King's Speech.srt\": \"tarih\",\n",
    "    \"Bohemian Rhapsody.srt\": \"müzik\",\n",
    "    \"Superbad.srt\": \"komedi\",\n",
    "    \"The Exorcist.srt\": \"korku\",\n",
    "    \"Inside Out.srt\": \"animasyon\",\n",
    "    \"Rush.srt\": \"spor\",\n",
    "    \"Children of Men.srt\": \"distoptik\",\n",
    "    \"The Silence of the Lambs.srt\": \"polisiye\",\n",
    "    \"La La Land.srt\": \"romantik\",\n",
    "    \"Harry Potter and the Sorcerer's Stone.srt\": \"fantastik\",\n",
    "    \"Die Hard.srt\": \"aksiyon\",\n",
    "    \"Forrest Gump.srt\": \"dram\",\n",
    "    \"Prisoners.srt\": \"gerilim\",\n",
    "    \"The Godfather.srt\": \"suç\",\n",
    "    \"Schindler's List.srt\": \"tarih\",\n",
    "    \"A Star is Born.srt\": \"müzik\",\n",
    "    \"Anchorman.srt\": \"komedi\",\n",
    "    \"Hereditary.srt\": \"korku\",\n",
    "    \"Toy Story.srt\": \"animasyon\",\n",
    "    \"The Fighter.srt\": \"spor\",\n",
    "    \"The Road.srt\": \"distoptik\",\n",
    "    \"Zodiac.srt\": \"polisiye\"\n",
    "}\n"
   ],
   "id": "639856372817bd50",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:29:53.020843Z",
     "start_time": "2025-05-09T11:29:53.013454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_labels_to_dataframe(df, label_dict):\n",
    "    \"\"\"DataFrame'e etiketleri ekler\"\"\"\n",
    "    df['Etiket'] = df['Film_Name'].apply(lambda x: label_dict.get(x + '.srt', 'bilinmiyor'))\n",
    "    return df\n"
   ],
   "id": "1e319f05289235d2",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:29:55.240314Z",
     "start_time": "2025-05-09T11:29:55.220310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "def analyze_term_frequencies(df):\n",
    "    \"\"\"Her film türü için en sık kullanılan kelimeleri analiz eder\"\"\"\n",
    "    genre_keywords = {}\n",
    "    \n",
    "    for genre in df['Etiket'].unique():\n",
    "        # Bu türdeki tüm cümleleri al\n",
    "        genre_sentences = df[df['Etiket'] == genre]['Processed_Sentence'].str.cat(sep=' ')\n",
    "        # Kelimelere böl\n",
    "        words = word_tokenize(genre_sentences)\n",
    "        # En sık kullanılan 20 kelimeyi bul\n",
    "        word_counts = Counter(words).most_common(20)\n",
    "        genre_keywords[genre] = word_counts\n",
    "    \n",
    "    return genre_keywords"
   ],
   "id": "e24fcf109b6a7eae",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T11:40:25.592137Z",
     "start_time": "2025-05-09T11:29:58.636037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    # Altyazı dosyalarının bulunduğu klasör\n",
    "    dosya_klasoru = Path(r\"C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\Filmler\")\n",
    "    \n",
    "    # 1. Tüm dosyaları işle\n",
    "    print(\"Dosyalar işleniyor...\")\n",
    "    final_df = process_all_files(dosya_klasoru)\n",
    "    \n",
    "    # 2. Etiketleri ekle\n",
    "    print(\"Etiketler ekleniyor...\")\n",
    "    labeled_df = add_labels_to_dataframe(final_df, film_etiketleri)\n",
    "    \n",
    "    # 3. Kelime sıklığı analizi yap\n",
    "    print(\"Kelime sıklığı analizi yapılıyor...\")\n",
    "    genre_keywords = analyze_term_frequencies(labeled_df)\n",
    "    \n",
    "    # Sonuçları kaydet\n",
    "    output_dir = Path(r\"C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler4\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)  # Klasör yoksa oluştur\n",
    "    \n",
    "    # Tüm verileri tek CSV'de kaydet - Sadece işlenmiş cümle ve etiket ile\n",
    "    all_data_path = output_dir / \"tum_filmler_etiketli_stemmed.csv\"\n",
    "    labeled_df[['Film_Name', 'Processed_Sentence', 'Etiket']].to_csv(all_data_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Tüm veriler kaydedildi: {all_data_path}\")\n",
    "    \n",
    "    # Filmler ayrı ayrı CSV'ler halinde kaydet - Sadece işlenmiş cümle ve etiket ile\n",
    "    for film_adi, grup in labeled_df.groupby('Film_Name'):\n",
    "        # Dosya adındaki geçersiz karakterleri temizle\n",
    "        safe_name = re.sub(r'[\\\\/*?:\"<>|]', \"_\", film_adi)\n",
    "        file_path = output_dir / f\"{safe_name}_etiketli_stemmed.csv\"\n",
    "        \n",
    "        # Yalnızca işlenmiş cümle ve etiket sütunları\n",
    "        grup[['Processed_Sentence', 'Etiket']].to_csv(file_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"Kaydedildi: {file_path}\")\n",
    "    \n",
    "    # Türlere göre sık kelime analizi sonuçlarını kaydet\n",
    "    with open(output_dir / \"tur_kelime_analizi.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for genre, keywords in genre_keywords.items():\n",
    "            f.write(f\"Film Türü: {genre}\\n\")\n",
    "            for word, count in keywords:\n",
    "                f.write(f\"  {word}: {count}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    \n",
    "    print(\"İşlem tamamlandı!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "1b16196feaa8eb39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dosyalar işleniyor...\n",
      "İşleniyor: A Star is Born.srt\n",
      "İşleniyor: Anchorman.srt\n",
      "İşleniyor: Blade Runner.srt\n",
      "İşleniyor: Bohemian Rhapsody.srt\n",
      "İşleniyor: Children of Men.srt\n",
      "İşleniyor: Die Hard.srt\n",
      "İşleniyor: Forrest Gump.srt\n",
      "İşleniyor: Frozen.srt\n",
      "İşleniyor: Full Metal Jacket.srt\n",
      "İşleniyor: Gone Girl.srt\n",
      "İşleniyor: Goodfellas.srt\n",
      "İşleniyor: Harry Potter and the Sorcerer's Stone.srt\n",
      "İşleniyor: Hereditary.srt\n",
      "İşleniyor: Inception.srt\n",
      "İşleniyor: Inside Out.srt\n",
      "İşleniyor: Interstellar.srt\n",
      "İşleniyor: La La Land.srt\n",
      "İşleniyor: Leon.srt\n",
      "İşleniyor: Mad Max.srt\n",
      "İşleniyor: Pride & Prejudice.srt\n",
      "İşleniyor: Prisoners.srt\n",
      "İşleniyor: Requiem for a Dream.srt\n",
      "İşleniyor: Rocky.srt\n",
      "İşleniyor: Rush.srt\n",
      "İşleniyor: Saving Private Ryan.srt\n",
      "İşleniyor: Schindler's List.srt\n",
      "İşleniyor: Se7en.srt\n",
      "İşleniyor: Shutter Island.srt\n",
      "İşleniyor: Stardust.srt\n",
      "İşleniyor: Superbad.srt\n",
      "İşleniyor: The Conjuring.srt\n",
      "İşleniyor: The Exorcist.srt\n",
      "İşleniyor: The Fighter.srt\n",
      "İşleniyor: The Godfather.srt\n",
      "İşleniyor: The Hangover.srt\n",
      "İşleniyor: The King's Speech.srt\n",
      "İşleniyor: The Lord Of The Rings.srt\n",
      "İşleniyor: The Matrix.srt\n",
      "İşleniyor: The Pianist.srt\n",
      "İşleniyor: The Road.srt\n",
      "İşleniyor: The Shawshank Redemption.srt\n",
      "İşleniyor: The Silence of the Lambs.srt\n",
      "İşleniyor: Titanic.srt\n",
      "İşleniyor: Toy Story.srt\n",
      "İşleniyor: Whiplash.srt\n",
      "İşleniyor: Zodiac.srt\n",
      "Etiketler ekleniyor...\n",
      "Kelime sıklığı analizi yapılıyor...\n",
      "Tüm veriler kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\tum_filmler_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\A Star is Born_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Anchorman_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Blade Runner_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Bohemian Rhapsody_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Children of Men_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Die Hard_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Forrest Gump_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Frozen_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Full Metal Jacket_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Gone Girl_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Goodfellas_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Harry Potter and the Sorcerer's Stone_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Hereditary_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Inception_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Inside Out_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Interstellar_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\La La Land_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Leon_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Mad Max_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Pride & Prejudice_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Prisoners_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Requiem for a Dream_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Rocky_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Rush_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Saving Private Ryan_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Schindler's List_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Se7en_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Shutter Island_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Stardust_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Superbad_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\The Conjuring_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\The Exorcist_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\The Fighter_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\The Godfather_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\The Hangover_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\The King's Speech_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\The Lord Of The Rings_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\The Matrix_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\The Pianist_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\The Road_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\The Shawshank Redemption_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\The Silence of the Lambs_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Titanic_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Toy Story_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Whiplash_etiketli_stemmed.csv\n",
      "Kaydedildi: C:\\Users\\Melek\\yapayZeka\\FilmTemaAnaliziProje\\İşlenmişVeriler3\\Zodiac_etiketli_stemmed.csv\n",
      "İşlem tamamlandı!\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
